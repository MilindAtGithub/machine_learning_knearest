{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This is the tutorial to Predict the flower based on the KNearest Algorithm\n",
    "    Note: This is based on the sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    First Getting the Sample Data loaded and printing meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of iris_dataset: \n",
      "['target_names', 'data', 'target', 'DESCR', 'feature_names']\n",
      "('Targets:', array(['setosa', 'versicolor', 'virginica'], dtype='|S10'))\n",
      "('Features:', ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))\n",
    "print(\"Targets:\",iris_dataset['target_names'])\n",
    "print(\"Features:\",iris_dataset['feature_names'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Check the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data: <type 'numpy.ndarray'>\n",
      "Shape of data: (150, 4)\n",
      "First five columns of data:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Type of target: <type 'numpy.ndarray'>\n",
      "Shape of target: (150,)\n",
      "Target:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of data: {}\".format(type(iris_dataset['data'])))\n",
    "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))\n",
    "print(\"First five columns of data:\\n{}\".format(iris_dataset['data'][:5]))\n",
    "print(\"Type of target: {}\".format(type(iris_dataset['target'])))\n",
    "print(\"Shape of target: {}\".format(iris_dataset['target'].shape))\n",
    "print(\"Target:\\n{}\".format(iris_dataset['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train Data', (112, 4))\n",
      "('Train Target', (112,))\n",
      "('Test_Data', (38, 4))\n",
      "('Test_Target', (38,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_Data, Test_Data, Train_Target, Test_Target = train_test_split(\n",
    "iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
    "print(\"Train Data\",Train_Data.shape)\n",
    "print(\"Train Target\", Train_Target.shape)\n",
    "print(\"Test_Data\", Test_Data.shape)\n",
    "print(\"Test_Target\", Test_Target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train Data And Target are matching so no data inconsitency here.\n",
    "    Now lets do Scatter Plotter with pair plot\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mglearn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8fe4d875fa3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmglearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0miris_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest_Data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m grr = pd.scatter_matrix(iris_dataframe, c=Test_Target, figsize=(15, 15), marker='o',\n\u001b[1;32m      5\u001b[0m hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mglearn"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import mglearn\n",
    "iris_dataframe = pd.DataFrame(Test_Data, columns=iris_dataset.feature_names)\n",
    "grr = pd.scatter_matrix(iris_dataframe, c=Test_Target, figsize=(15, 15), marker='o',\n",
    "hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
